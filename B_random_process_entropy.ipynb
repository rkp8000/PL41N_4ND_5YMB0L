{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a29fc994",
   "metadata": {},
   "source": [
    "We want to calculate the joint entropy of infinitely finely spaced measurements of a 1-D random process, where the domain is bounded and the response is binned at resolution $1/\\Delta r$. Specifically, given \n",
    "\n",
    "$$r(\\tau) = [1 - e^{-1/\\tau}]\\sum_{m=0}^{\\infty}e^{-m/\\tau}s_m$$\n",
    "\n",
    "where $\\{s_m\\}$ is an infinite binary string sampled from some distribution (e.g. i.i.d. Bernoulli variables), let $\\mathbf{r} = [r_0, ..., r_L]$ and $a(\\tau) = \\exp(-1/\\tau)$, $a_k = k/L$ with \n",
    "\n",
    "$$r_k \\equiv r(\\tau_k) = r(-1/\\log[a_k]) = r(-1/\\log[k/L])$$\n",
    "\n",
    "i.e.\n",
    "\n",
    "$$r_k = [1 - k/L]\\sum_{m=0}^{\\infty}(k/L)^ms_m$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3576082a",
   "metadata": {},
   "source": [
    "so that $k/L = 0$ maps to $\\tau = 0$ and $k/L = 1$ maps to $\\tau = \\infty$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee86f90",
   "metadata": {},
   "source": [
    "We want to compute\n",
    "\n",
    "$$H[r(\\tau)] \\equiv \\lim_{L \\rightarrow \\infty} H[r_0, ..., r_L]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25565d74",
   "metadata": {},
   "source": [
    "First note that $H[r(\\tau)]$ is finite. Roughly speaking, since $r$ is a smooth function of $a$: $$r(\\tau) = [1 - a]\\sum_{m=0}^\\infty a^ms_m$$, eventually taking finer and finer measurements will yield no new information, since each measurement at $a_k$ will be almost identical to the measurement at $a_{k+1}$, and we need only consider $0 \\leq a \\leq 1$, so we are measuring $r$ over a bounded domain. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95313f43",
   "metadata": {},
   "source": [
    "Although $H[r(\\tau)]$ may be analytically solvable for i.i.d. $s_m$, we would like a way to estimate it from a collection of samples of $r(\\tau)$, so we can compare the i.i.d. case to when $\\{s_m\\}$ has higher order statistics. This is tricky, however, since $\\mathbf{r}$ is high-dimensional and for most reasonable resolutions $1/\\Delta r$, most of the $(1/\\Delta r)^{L+1}$ bins will contain at most one sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae1fcfa",
   "metadata": {},
   "source": [
    "Note: we can estimate entropy empirically via monte carlo methods if we can compute $-\\log p$ of each sample, since then we can estimate $$\\hat{H}[r_0, ..., r_L] = \\frac{1}{N} \\sum_{\\mathbf{r}_{sample}} -\\log p(\\mathbf{r}_{sample})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d867338",
   "metadata": {},
   "source": [
    "Possible directions for solving this:\n",
    "\n",
    "1. Start with very large bin size and compute entropy from histogram + finite sampling corrections, decrease slowly, and extrapolate dependence of $H$ on $\\Delta r$ beyond limitations from finite sampling.\n",
    "2. Take advantage of the structure of the full support of $P(\\mathbf{r})$ that allows to define a similarity among the different samples of $r(\\tau)$. Intuitively, samples with a lot of other samples nearby should correspond to regions of high probability whereas samples with few neighbors should correspond to low probability.\n",
    "3. Maybe we can't solve it directly, but maybe we can compare entropies given two different distributions over $\\{s_m\\}$, which is our ultimate goal anyway.\n",
    "4. Directly compute entropies from histograms for small numbers of measurements, slowly increase number of measurements and see whether e.g. entropy of one set of samples stays higher than other set of samples..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d481321",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
